{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"G:/BracU/Thesis/Federated Dataset/PlantVillage/Train\"\n",
    "test_dir = \"G:/BracU/Thesis/Federated Dataset/PlantVillage/Test\"\n",
    "client_dirs = glob(source_dir+ \"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4946 images belonging to 15 classes.\n",
      "Found 544 images belonging to 15 classes.\n",
      "Found 4948 images belonging to 15 classes.\n",
      "Found 544 images belonging to 15 classes.\n",
      "Found 4935 images belonging to 15 classes.\n",
      "Found 541 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "input_shape = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "generators_train_client = []\n",
    "generators_val_client = []\n",
    "\n",
    "for i in range(0, len(client_dirs)):\n",
    "    datagen_train = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
    "    generator_train = datagen_train.flow_from_directory(directory=client_dirs[i],\n",
    "                                                    target_size=input_shape,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='sparse',\n",
    "                                                    subset=\"training\",\n",
    "                                                    shuffle=True)\n",
    "    generator_val = datagen_train.flow_from_directory(directory=client_dirs[i],\n",
    "                                                    target_size=input_shape,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    subset=\"validation\",\n",
    "                                                    class_mode='sparse',\n",
    "                                                    shuffle=True)\n",
    "    generators_train_client.append(generator_train)\n",
    "    generators_val_client.append(generator_val)\n",
    "num_classes = generators_train_client[0].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4180 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "generators_test = datagen_train.flow_from_directory(directory=test_dir,\n",
    "                                                    target_size=input_shape,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='sparse',\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, BatchNormalization, ReLU, Input\n",
    "\n",
    "\n",
    "class Involution(Layer):\n",
    "    def __init__(self, channels, kernel_size=3, reduction_ratio=2, group_channels=1, **kwargs):\n",
    "        super(Involution, self).__init__(**kwargs)  # Pass kwargs to the base Layer class\n",
    "        self.channels = channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "        self.group_channels = group_channels\n",
    "        self.groups = channels // group_channels\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.reduce_channels = self.channels // self.reduction_ratio\n",
    "        self.kernel_gen = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(self.reduce_channels, kernel_size=1, padding='same', use_bias=False),\n",
    "            BatchNormalization(),\n",
    "            ReLU(),\n",
    "            tf.keras.layers.Conv2D(self.kernel_size * self.kernel_size * self.groups, kernel_size=1, padding='same')\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size, height, width, in_channels = tf.shape(inputs)[0], tf.shape(inputs)[1], tf.shape(inputs)[2], tf.shape(inputs)[3]\n",
    "        \n",
    "        # Generate kernels\n",
    "        kernels = self.kernel_gen(inputs)\n",
    "        kernels = tf.reshape(kernels, (batch_size, height, width, self.kernel_size * self.kernel_size, self.groups))\n",
    "        kernels = tf.nn.softmax(kernels, axis=-2)\n",
    "\n",
    "        # Unfold input\n",
    "        x_unfold = tf.image.extract_patches(inputs, sizes=[1, self.kernel_size, self.kernel_size, 1], \n",
    "                                            strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding='SAME')\n",
    "        x_unfold = tf.reshape(x_unfold, (batch_size, height, width, self.kernel_size * self.kernel_size, self.groups))\n",
    "\n",
    "        # Apply involution\n",
    "        outputs = tf.reduce_sum(kernels * x_unfold, axis=-2)\n",
    "        outputs = tf.reshape(outputs, (batch_size, height, width, self.channels))\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'channels': self.channels,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'reduction_ratio': self.reduction_ratio,\n",
    "            'group_channels': self.group_channels,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " involution (Involution)     (None, 128, 128, 3)       61        \n",
      "                                                                 \n",
      " involution_1 (Involution)   (None, 128, 128, 3)       61        \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 3)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " involution_2 (Involution)   (None, 64, 64, 3)         61        \n",
      "                                                                 \n",
      " involution_3 (Involution)   (None, 64, 64, 3)         61        \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 3)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " involution_4 (Involution)   (None, 32, 32, 3)         61        \n",
      "                                                                 \n",
      " involution_5 (Involution)   (None, 32, 32, 3)         61        \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 3)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " involution_6 (Involution)   (None, 16, 16, 3)         61        \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 16, 16, 3)         0         \n",
      "                                                                 \n",
      " involution_7 (Involution)   (None, 16, 16, 3)         61        \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 16, 16, 3)         0         \n",
      "                                                                 \n",
      " involution_8 (Involution)   (None, 16, 16, 3)         61        \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 16, 16, 3)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 8, 8, 3)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              197632    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 17)                17425     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,265,206\n",
      "Trainable params: 1,265,188\n",
      "Non-trainable params: 18\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_invnet_vgg16_optimized(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Block 1\n",
    "    x = Involution(channels=3, kernel_size=3)(inputs)\n",
    "    x = Involution(channels=3, kernel_size=3)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    \n",
    "    # Block 2\n",
    "    x = Involution(channels=3, kernel_size=3)(x)\n",
    "    x = Involution(channels=3, kernel_size=3)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    \n",
    "    # Block 3\n",
    "    x = Involution(channels=3, kernel_size=3)(x)\n",
    "    x = Involution(channels=3, kernel_size=3)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    \n",
    "    # Block 4\n",
    "    x = Involution(channels=3, kernel_size=3)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Involution(channels=3, kernel_size=3)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Involution(channels=3, kernel_size=3)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    \n",
    "    # Fully connected layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (128, 128, 3)\n",
    "num_classes = 17\n",
    "\n",
    "opt = Adam(0.001)\n",
    "\n",
    "# Build and compile the InvNet model\n",
    "model = build_invnet_vgg16_optimized(input_shape, num_classes)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/50...\n",
      "Training local model 1/3...\n",
      "155/155 [==============================] - 17s 92ms/step - loss: 2.6311 - accuracy: 0.1442 - val_loss: 2.5648 - val_accuracy: 0.1562\n",
      "Training local model 2/3...\n",
      "155/155 [==============================] - 18s 97ms/step - loss: 2.6402 - accuracy: 0.1431 - val_loss: 2.5590 - val_accuracy: 0.1691\n",
      "Training local model 3/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.6316 - accuracy: 0.1443 - val_loss: 2.5456 - val_accuracy: 0.1590\n",
      "Round 2/50...\n",
      "Training local model 1/3...\n",
      "155/155 [==============================] - 18s 97ms/step - loss: 2.5752 - accuracy: 0.1535 - val_loss: 2.5571 - val_accuracy: 0.1636\n",
      "Training local model 2/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.5805 - accuracy: 0.1556 - val_loss: 2.5660 - val_accuracy: 0.1636\n",
      "Training local model 3/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.5657 - accuracy: 0.1576 - val_loss: 2.5469 - val_accuracy: 0.1664\n",
      "Round 3/50...\n",
      "Training local model 1/3...\n",
      "155/155 [==============================] - 18s 91ms/step - loss: 2.5686 - accuracy: 0.1545 - val_loss: 2.5540 - val_accuracy: 0.1654\n",
      "Training local model 2/3...\n",
      "155/155 [==============================] - 17s 91ms/step - loss: 2.5766 - accuracy: 0.1566 - val_loss: 2.5484 - val_accuracy: 0.1710\n",
      "Training local model 3/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.5615 - accuracy: 0.1556 - val_loss: 2.5427 - val_accuracy: 0.1664\n",
      "Round 4/50...\n",
      "Training local model 1/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.5623 - accuracy: 0.1575 - val_loss: 2.5391 - val_accuracy: 0.1673\n",
      "Training local model 2/3...\n",
      "155/155 [==============================] - 17s 91ms/step - loss: 2.5648 - accuracy: 0.1593 - val_loss: 2.5415 - val_accuracy: 0.1710\n",
      "Training local model 3/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.5529 - accuracy: 0.1574 - val_loss: 2.5384 - val_accuracy: 0.1664\n",
      "Round 5/50...\n",
      "Training local model 1/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.5644 - accuracy: 0.1579 - val_loss: 2.5360 - val_accuracy: 0.1673\n",
      "Training local model 2/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.5712 - accuracy: 0.1580 - val_loss: 2.5373 - val_accuracy: 0.1728\n",
      "Training local model 3/3...\n",
      "155/155 [==============================] - 17s 91ms/step - loss: 2.5581 - accuracy: 0.1591 - val_loss: 2.5423 - val_accuracy: 0.1664\n",
      "Round 6/50...\n",
      "Training local model 1/3...\n",
      "155/155 [==============================] - 17s 91ms/step - loss: 2.5604 - accuracy: 0.1597 - val_loss: 2.5372 - val_accuracy: 0.1673\n",
      "Training local model 2/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.5672 - accuracy: 0.1580 - val_loss: 2.5318 - val_accuracy: 0.1710\n",
      "Training local model 3/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.5527 - accuracy: 0.1609 - val_loss: 2.5324 - val_accuracy: 0.1664\n",
      "Round 7/50...\n",
      "Training local model 1/3...\n",
      "155/155 [==============================] - 17s 91ms/step - loss: 2.5623 - accuracy: 0.1579 - val_loss: 2.5366 - val_accuracy: 0.1673\n",
      "Training local model 2/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.5664 - accuracy: 0.1589 - val_loss: 2.5322 - val_accuracy: 0.1710\n",
      "Training local model 3/3...\n",
      "155/155 [==============================] - 17s 89ms/step - loss: 2.5572 - accuracy: 0.1597 - val_loss: 2.5351 - val_accuracy: 0.1664\n",
      "Round 8/50...\n",
      "Training local model 1/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.5615 - accuracy: 0.1575 - val_loss: 2.5337 - val_accuracy: 0.1673\n",
      "Training local model 2/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.5622 - accuracy: 0.1593 - val_loss: 2.5322 - val_accuracy: 0.1710\n",
      "Training local model 3/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.5554 - accuracy: 0.1601 - val_loss: 2.5323 - val_accuracy: 0.1664\n",
      "Round 9/50...\n",
      "Training local model 1/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.5659 - accuracy: 0.1575 - val_loss: 2.5340 - val_accuracy: 0.1673\n",
      "Training local model 2/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.5681 - accuracy: 0.1572 - val_loss: 2.5415 - val_accuracy: 0.1691\n",
      "Training local model 3/3...\n",
      "155/155 [==============================] - 17s 91ms/step - loss: 2.5616 - accuracy: 0.1603 - val_loss: 2.5357 - val_accuracy: 0.1664\n",
      "Round 10/50...\n",
      "Training local model 1/3...\n",
      "155/155 [==============================] - 17s 90ms/step - loss: 2.5634 - accuracy: 0.1581 - val_loss: 2.5341 - val_accuracy: 0.1673\n",
      "Training local model 2/3...\n",
      "155/155 [==============================] - 18s 98ms/step - loss: 2.5692 - accuracy: 0.1586 - val_loss: 2.5379 - val_accuracy: 0.1691\n",
      "Training local model 3/3...\n",
      "155/155 [==============================] - 18s 95ms/step - loss: 2.5567 - accuracy: 0.1597 - val_loss: 2.5356 - val_accuracy: 0.1664\n",
      "Round 11/50...\n",
      "Training local model 1/3...\n",
      "155/155 [==============================] - 17s 93ms/step - loss: 2.5634 - accuracy: 0.1573 - val_loss: 2.5389 - val_accuracy: 0.1654\n",
      "Training local model 2/3...\n",
      " 89/155 [================>.............] - ETA: 5s - loss: 2.5619 - accuracy: 0.1566"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     local_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mopt, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Train the local model\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     \u001b[43mlocal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerators_train_client\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerators_val_client\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     local_models\u001b[38;5;241m.\u001b[39mappend(local_model)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Aggregating weights (Federated Averaging)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Build the initial global model\n",
    "global_model = build_invnet_vgg16_optimized(input_shape, num_classes)\n",
    "global_model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Simulate federated learning process\n",
    "\n",
    "\n",
    "\n",
    "num_clients = len(client_dirs)\n",
    "num_rounds = 50\n",
    "local_epochs = 1\n",
    "\n",
    "# List to store local models\n",
    "local_models = []\n",
    "\n",
    "for round_num in range(num_rounds):\n",
    "    print(f\"Round {round_num + 1}/{num_rounds}...\")\n",
    "    local_models = []  # Reset local models for each round\n",
    "    for client in range(num_clients):\n",
    "        print(f\"Training local model {client + 1}/{num_clients}...\")\n",
    "        local_model = tf.keras.models.clone_model(global_model)  # Clone the global model structure\n",
    "        local_model.set_weights(global_model.get_weights())  # Initialize with global model weights\n",
    "        \n",
    "        # Compile the local model\n",
    "        local_model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the local model\n",
    "        local_model.fit(generators_train_client[client], epochs=local_epochs, validation_data=generators_val_client[client])\n",
    "        local_models.append(local_model)\n",
    "\n",
    "    # Aggregating weights (Federated Averaging)\n",
    "    new_weights = [np.zeros_like(weight) for weight in global_model.get_weights()]\n",
    "\n",
    "    for local_model in local_models:\n",
    "        local_weights = local_model.get_weights()\n",
    "        for i in range(len(new_weights)):\n",
    "            new_weights[i] += local_weights[i] / num_clients\n",
    "\n",
    "    global_model.set_weights(new_weights)\n",
    "\n",
    "# Evaluate the global model\n",
    "print(\"Evaluating the global model...\")\n",
    "global_model.evaluate(generators_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
